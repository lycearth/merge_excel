import os
import io
import json
import pandas as pd
import streamlit as st

st.set_page_config(page_title="å¤šè¡¨åˆå¹¶å·¥å…·", layout="wide")

RULES_FILE = "rules.json"


# ========== å·¥å…·å‡½æ•° ==========
def load_rules():
    """åŠ è½½è§„åˆ™æ–‡ä»¶å¹¶è¿‡æ»¤æ‰æ—§æ ¼å¼"""
    if os.path.exists(RULES_FILE):
        try:
            with open(RULES_FILE, "r", encoding="utf-8") as f:
                rules = json.load(f)
            # å…¼å®¹æ—§æ ¼å¼ï¼Œç¡®ä¿æœ‰ weights
            for r in rules:
                if "weights" not in r:
                    r["weights"] = [1] * len(r["cols"])
            return rules
        except json.JSONDecodeError:
            return []
    return []


def save_rules(rules):
    """ä¿å­˜è§„åˆ™åˆ°æ–‡ä»¶"""
    with open(RULES_FILE, "w", encoding="utf-8") as f:
        json.dump(rules, f, ensure_ascii=False, indent=2)


def preview_file(file):
    """è¯»å–æ–‡ä»¶é¢„è§ˆç”¨"""
    if file.name.endswith(".csv"):
        return pd.read_csv(file, header=None)
    return pd.read_excel(file, header=None)


def read_file(file, header_row):
    """æŒ‰æŒ‡å®šè¡¨å¤´è¡Œè¯»å–æ–‡ä»¶"""
    if file.name.endswith(".csv"):
        return pd.read_csv(file, header=header_row)
    return pd.read_excel(file, header=header_row)


def find_name_col(columns):
    """è‡ªåŠ¨è¯†åˆ«å§“ååˆ—"""
    for col in columns:
        if "å§“å" in str(col):
            return col
    return None


# ========== çŠ¶æ€åˆå§‹åŒ– ==========
if "rules" not in st.session_state:
    st.session_state.rules = load_rules()

if "small_table_info" not in st.session_state:
    st.session_state.small_table_info = []


# ========== ä¸Šä¼ æ–‡ä»¶ ==========
st.title("ğŸ“Š å¤šä¸ªå°è¡¨æ ¼åˆå¹¶å¹¶å¡«å……åˆ°å¤§è¡¨æ ¼")

uploaded_files = st.file_uploader("ä¸Šä¼ å°è¡¨æ ¼ï¼ˆå¤šä¸ªï¼‰", type=["xlsx", "xls", "csv"], accept_multiple_files=True)
big_table_file = st.file_uploader("ä¸Šä¼ å¤§è¡¨æ ¼æ¨¡æ¿", type=["xlsx", "xls", "csv"])

# ========== å¤„ç†å°è¡¨ ==========
if uploaded_files:
    st.subheader("ğŸ“„ é…ç½®æ¯ä¸ªå°è¡¨çš„è¡¨å¤´è¡Œå’Œå§“ååˆ—")
    st.session_state.small_table_info = []

    for idx, file in enumerate(uploaded_files):
        with st.expander(f"ğŸ“„ {file.name}", expanded=(idx == 0)):
            preview_df = preview_file(file)
            st.dataframe(preview_df.head(5))

            header_row = st.number_input(
                f"è¡¨ {idx+1} è¡¨å¤´è¡Œ (ä»0å¼€å§‹)", min_value=0, max_value=10, value=0, key=f"header_{idx}"
            )
            df = read_file(file, header_row)
            auto_name_col = find_name_col(df.columns)

            name_col = st.selectbox(
                f"è¡¨ {idx+1} å§“ååˆ—",
                df.columns.tolist(),
                index=df.columns.get_loc(auto_name_col) if auto_name_col in df.columns else 0,
                key=f"namecol_{idx}"
            )

            st.session_state.small_table_info.append({
                "file": file.name,
                "header_row": header_row,
                "name_col": name_col,
                "df": df
            })


# ========== å¤„ç†å¤§è¡¨ ==========
if st.session_state.small_table_info and big_table_file:
    # è¯»å–å¤§è¡¨
    big_header_row = st.number_input(
        "å¤§è¡¨è¡¨å¤´è¡Œ (ä»0å¼€å§‹)", min_value=0, max_value=10, value=0, key="big_header"
    )
    big_df = read_file(big_table_file, big_header_row)

    auto_name_col_big = find_name_col(big_df.columns)
    big_name_col = st.selectbox(
        "å¤§è¡¨å§“ååˆ—",
        big_df.columns.tolist(),
        index=big_df.columns.get_loc(auto_name_col_big) if auto_name_col_big in big_df.columns else 0,
        key="big_namecol"
    )

    st.subheader("ğŸ›  é…ç½®è®¡ç®—è§„åˆ™")

    table_idx = st.selectbox(
        "é€‰æ‹©å°è¡¨æ¥æº",
        options=list(range(len(st.session_state.small_table_info))),
        index=0,
        format_func=lambda i: f"è¡¨ {i+1} ({st.session_state.small_table_info[i]['file']})",
        key="table_idx"
    )

    cols = st.multiselect(
        "é€‰æ‹©ç”¨äºè®¡ç®—çš„åˆ—",
        options=[
            c for c in st.session_state.small_table_info[table_idx]["df"].columns
            if c != st.session_state.small_table_info[table_idx]["name_col"]
        ],
        key="selected_cols"
    )

    # é€‰æ‹©æ¯åˆ—çš„è¿ç®—ç¬¦(+/-) å’Œ æƒé‡
    col_ops = []
    col_weights = []

    if cols:
        st.markdown("#### âš–ï¸ è®¾ç½®æ¯åˆ—çš„è¿ç®—ç¬¦å’Œæƒé‡")
        for col in cols:
            c1, c2, c3 = st.columns([1, 1, 2])
            with c1:
                op = st.selectbox(f"{col} è¿ç®—ç¬¦", ["+", "-"], key=f"op_{col}")
            with c2:
                w = st.number_input(f"{col} æƒé‡", value=1.0, step=1.0, key=f"weight_{col}")
            col_ops.append(op)
            col_weights.append(w)

    target = st.selectbox("é€‰æ‹©ç»“æœå¡«å…¥çš„å¤§è¡¨åˆ—", big_df.columns.tolist())

    if st.button("â• æ·»åŠ è§„åˆ™"):
        if cols and target:
            st.session_state.rules.append({
                "table": table_idx,
                "cols": cols,
                "ops": col_ops,       # ä¿å­˜æ¯åˆ—çš„è¿ç®—ç¬¦
                "weights": col_weights,
                "target": target
            })
            save_rules(st.session_state.rules)
            st.success("âœ… è§„åˆ™å·²ä¿å­˜")
        else:
            st.warning("è¯·é€‰æ‹©åˆ—å¹¶å¡«å†™ç›®æ ‡åˆ—å")

else:
    st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ è‡³å°‘ä¸€ä¸ªå°è¡¨å’Œä¸€ä¸ªå¤§è¡¨ï¼Œæ‰èƒ½é…ç½®è®¡ç®—è§„åˆ™")

# ========== æ˜¾ç¤ºè§„åˆ™ ==========
if st.session_state.rules:
    st.subheader("ğŸ“‹ å½“å‰è§„åˆ™")
    for i, r in enumerate(st.session_state.rules):
        table_name = st.session_state.small_table_info[r["table"]]["file"] \
            if r["table"] < len(st.session_state.small_table_info) else f"è¡¨ {r['table']+1}"
        cols_weights = " + ".join([f"{c}Ã—{w}" for c, w in zip(r["cols"], r["weights"])])
        st.write(f"{i+1}. {table_name}: {cols_weights} â†’ {r['target']}")

        if st.button(f"ğŸ—‘ åˆ é™¤ç¬¬{i+1}æ¡è§„åˆ™", key=f"del_{i}"):
            st.session_state.rules.pop(i)
            save_rules(st.session_state.rules)
            st.rerun()

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è§„åˆ™"):
        st.session_state.rules = []
        save_rules([])
        st.rerun()


# ========== ç”Ÿæˆç»“æœ ==========
if st.session_state.rules and st.button("ğŸš€ ç”Ÿæˆç»“æœ"):
    # âœ… ç¡®ä¿ big_df å­˜åœ¨
    if "big_df" not in locals():
        st.error("è¯·å…ˆä¸Šä¼ å¹¶è¯»å–å¤§è¡¨æ–‡ä»¶")
    else:
        result_df = big_df.copy()

        # ç»Ÿä¸€å§“ååˆ—æ ¼å¼
        def normalize_names(series):
            return (
                series.astype(str)
                .str.strip()
                .str.replace("\u3000", " ")
                .str.replace("\xa0", " ")
            )

        result_df[big_name_col] = normalize_names(result_df[big_name_col])

        for rule in st.session_state.rules:
            try:
                info = st.session_state.small_table_info[rule["table"]]
                df = info["df"].copy()
                name_col = info["name_col"]
                df[name_col] = normalize_names(df[name_col])

                grouped = df.groupby(name_col)
                values = pd.Series(0.0, index=df[name_col].unique())

                # âœ… æŒ‰è¿ç®—ç¬¦å’Œæƒé‡è®¡ç®—
                for col, op, w in zip(rule["cols"], rule["ops"], rule["weights"]):
                    col_sum = grouped[col].sum() * w
                    col_sum = col_sum.reindex(values.index, fill_value=0)
                    values = values + col_sum if op == "+" else values - col_sum

                values_df = values.reset_index()
                values_df.columns = [name_col, rule["target"]]

                # âœ… è°ƒè¯•è¾“å‡ºä¸€æ¬¡
                st.write(f"ğŸ” è§„åˆ™ {rule['target']} è®¡ç®—ç»“æœï¼š", values_df.head())

                mapping = dict(zip(values_df[name_col], values_df[rule["target"]]))

                # âœ… åªå¯¹å§“åéç©ºçš„è¡Œèµ‹å€¼
                name_mask = big_df[big_name_col].notna() & (
                    big_df[big_name_col].astype(str).str.strip() != ""
                )
                result_df.loc[name_mask, rule["target"]] = (
                    result_df.loc[name_mask, big_name_col].map(mapping)
                )

                # âœ… èµ‹å€¼å®Œæˆåï¼Œå¼ºåˆ¶è¯¥åˆ—ä¸ºæ•°å€¼ç±»å‹
                result_df[rule["target"]] = pd.to_numeric(result_df[rule["target"]], errors="coerce")


            except Exception as e:
                st.error(f"è§„åˆ™ {rule['target']} è®¡ç®—å¤±è´¥ï¼š{e}")

        # âœ… è½¬æ¢ç±»å‹ï¼Œé¿å…æ•°å­—åˆ—å˜æˆæ–‡æœ¬
        result_df = result_df.convert_dtypes()

        # âœ… å¤„ç†ç©ºå€¼ï¼šæ•°å­—åˆ—ä¿æŒæ•°å­—ï¼Œå­—ç¬¦ä¸²åˆ—æ›¿æ¢ä¸ºç©ºç™½
        for col in result_df.columns:
            if pd.api.types.is_numeric_dtype(result_df[col]):
                result_df[col] = result_df[col].astype("Float64")
            else:
                result_df[col] = result_df[col].astype(str).replace({"nan": "", "<NA>": ""})

        st.subheader("ğŸ“¥ ä¸‹è½½ç»“æœ")
        output = io.BytesIO()
        result_df.to_excel(output, index=False)
        st.download_button(
            "â¬‡ï¸ ç‚¹å‡»ä¸‹è½½åˆå¹¶ç»“æœ",
            data=output.getvalue(),
            file_name="åˆå¹¶ç»“æœ.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
